{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# Llenar el csv con los nombres de las clases y no con indices.\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "import aifc\n",
    "import math\n",
    "from numpy import NaN, Inf, arange, isscalar, array\n",
    "import pandas as pd\n",
    "from scipy.fftpack import rfft\n",
    "from scipy.fftpack import fft\n",
    "from scipy.fftpack.realtransforms import dct\n",
    "from scipy.signal import fftconvolve\n",
    "from matplotlib.mlab import find\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as la\n",
    "import audioBasicIO\n",
    "import utilities\n",
    "\n",
    "eps = numpy.finfo(float).eps\n",
    "\n",
    "from scipy.signal import lfilter, hamming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Crossing Rate\n",
    "\n",
    "- La taza de cruces por cero, (**Zero-crossing rate**) es la taza de cambios de signo a lo largo de una señal, por ejemplo la taza en al cual cambia de positivo a negativo o viceversa. Esta caracteristica ha sido utilizada en aplicaciones de reconocimiento del habla y en la recuperacion de informacion musical (MIR).\n",
    "- Se le considera una caracteristica importante para clasificar sonidos de percusion.\n",
    "- La taza de cruces por cero es usada en aplicaciones como la deteccion  de voz (**Voice activity detection**) Ejemplo: Detectar si la voz es humana esta presente en el audio o no.\n",
    "\n",
    "Antecedentes del uso de Zero Crossing rate:\n",
    "\n",
    "\n",
    "### Energia ó Potencia de la señal.\n",
    "\n",
    "- Sea xi(n), n = 1,...,Wl la secuencia de muestras de audio del i-esimo marco, donde Wl es la longitud del marco. La energia a corto plazo se define como la suma de los cuadrados de las muestras, usualmente normalizado diviendola entre la logitud del marco.\n",
    "\n",
    "- La energia es la caracteristica mas basica en el procesamiento de señales del habla. Este juega un rol vital en el reconomiento de emociones. Por ejemplo las señales que corresponden a la felicidad y la ira contienen mas energia que por ejemplo la tristeza.\n",
    "\n",
    "Antecedentes:\n",
    "Emotion Recognition and Classification in Speech using\n",
    "Artificial Neural Networks\n",
    "\n",
    "### Entropia de la energia\n",
    "- La entropia de una señal es una medida de la cantidad de informacion que esta trae, su excelente desempeño en aplicaciones de reonocimiento de voz y actividad de señal ha generado que esta caracteristica sea usada incluso en el contexto del procesamiento de imagenes.\n",
    "\n",
    "- Puede ser interpretada como una medida de cambios abrutos en el nivel de energia de una señal de audio.\n",
    "\n",
    "- Pequeñas variaciones en los valores de muestra generan producen pequeñas pertubaciones en la medida de la entropia.\n",
    "\n",
    "- La entropia es usada en el procesamiento de señales para separar la señal del ruido.\n",
    "- Es usado en el reconocimiento de voz, detecction de actividad, analisis spectral y clasificacion de marcos (separaciond de ruido y tono).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Time-domain audio features \"\"\"\n",
    "\n",
    "\n",
    "def stZCR(frame):\n",
    "    \"\"\"Computes zero crossing rate of frame\"\"\"\n",
    "    count = len(frame)\n",
    "    countZ = numpy.sum(numpy.abs(numpy.diff(numpy.sign(frame)))) / 2\n",
    "    return (numpy.float64(countZ) / numpy.float64(count-1.0))\n",
    "\n",
    "\n",
    "def stEnergy(frame):\n",
    "    \"\"\"Computes signal energy of frame\"\"\"\n",
    "    return numpy.sum(frame ** 2) / numpy.float64(len(frame))\n",
    "\n",
    "\n",
    "def stEnergyEntropy(frame, numOfShortBlocks=10):\n",
    "    \"\"\"Computes entropy of energy\"\"\"\n",
    "    Eol = numpy.sum(frame ** 2)    # total frame energy\n",
    "    L = len(frame)\n",
    "    subWinLength = int(numpy.floor(L / numOfShortBlocks))\n",
    "    if L != subWinLength * numOfShortBlocks:\n",
    "            frame = frame[0:subWinLength * numOfShortBlocks]\n",
    "    # subWindows is of size [numOfShortBlocks x L]\n",
    "    subWindows = frame.reshape(subWinLength, numOfShortBlocks, order='F').copy()\n",
    "\n",
    "    # Compute normalized sub-frame energies:\n",
    "    s = numpy.sum(subWindows ** 2, axis=0) / (Eol + numpy.finfo(float).eps)\n",
    "\n",
    "    # Compute entropy of the normalized sub-frame energies:\n",
    "    Entropy = -numpy.sum(s * numpy.log2(s + numpy.finfo(float).eps))\n",
    "    return Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Centroide Espectral\n",
    "- Es el centro de gravedad del spectro.\n",
    "- Este denota el punto de balace la magnitud del spectro.\n",
    "- Este captura las caracteristicas concernientes a la pendiente espectral.\n",
    "\n",
    "**Antecedentes**:\n",
    "Emotional Speech Recognition using Optimized\n",
    "Features \n",
    "\n",
    "### 5 Tono (Pitch)\n",
    "- Las señales de audio pueden ser categorizadas como quasi-periodicas y aperiodicas(como ruido). El termino \"quasi-periodico\" se refiere al hecho de algunas señales exhiben un comportamiento periodico. Dentro de las señales quasi-periodicas podemos encontrar los fonemas de las voz y la mayoria de señales de musica. \n",
    "\n",
    "- Por otra parte las señales de ruido incluyen los fonemas sordos, sonido de fondo, sonido ambiental, aplausos, disparos entre otros. En esta categoria tambien se encuentran los fonemas fricativos y sonidos de percusion.\n",
    "\n",
    "- Para la señales periodicas, la frecuencia equivalente a la longitud del periodo fundamental de la señal es conocido como la frecuencia fundamental y los algoritmos que estiman esta frecuencia se les conoce como: **Frecuency track algorithms**. \n",
    "\n",
    "- El tono estrictamentemente hablando es la frecuencia percibida, pero en la literatura el tono y la frecuencia fundamental son terminos intercambiables.\n",
    "\n",
    "\n",
    "### 6 Entropia Espectral\n",
    "- La entropía espectral se calcula de manera similar a la entropía de energía, sin embargo, se aplica en el dominio de la frecuencia.\n",
    "\n",
    "### 7 Flujo espectral (Spectral  Flux )\n",
    "\n",
    "- Denota el cambio del spectro local de una señal emocional. El flujo espectral indica que tan rapido cambia el espectro de potencia dentro de los marcos en la señal.\n",
    "\n",
    "Antecedentes:\n",
    "Emotional Speech Recognition using Optimized\n",
    "Features \n",
    "\n",
    "### 8 Caida espectral (Espectral roll-off)\n",
    "- La energia de una señal de habla que contiene informacion de una emocion es encontrada dentro de determiando rango  de frecuencias, La caida espectral indica el contenido de las frencuencias por debajo de las cuales ciertas fracciones de la cantidad total de energia se mantienen.\n",
    "\n",
    "- Dependiendo de las caracteristicas de la señal, es utilizado un valor entre 0.95 y 0.85 para el calculo.\n",
    "\n",
    "- La caida espectral ademas provee informacion de la forma espectral con al cual se determina la cantidad de componentes de frecuencias altas disponibles en la señal.\n",
    "\n",
    "Antecedentes:\n",
    "Emotional Speech Recognition using Optimized\n",
    "Features \n",
    "\n",
    "### 9-21 MFFC\n",
    "\n",
    "- Los Coeficientes ceptralales de las frecuencias de Mel (**MFCC**) han sido muy\n",
    "popular en el campo del análisis de voz. En la práctica, los MFCC son los\n",
    "coeficientes discretos de la transformación coseno del espectro de potencia logarítmica en la escala de Mel. Los MFCC\n",
    "ha sido ampliamente utilizado en reconocimiento de voz, agrupamiento de altavoces, reconocimiento de emociones y muchos otros tipos de aplicaciones de analisis de audio y apredizaje de maquina.\n",
    "\n",
    "- Caracterizan la maginitud del espectro, son comunmente utilizados en el reconocimiento de hablantes. \n",
    "\n",
    "- Son usados los 12 coeficientes mas importantes.\n",
    "\n",
    "\n",
    "### 23-33 Vector cromatico\n",
    "- Esta es una representación en 12 dimensiones de la energía espectral de una señal de audio.\n",
    "- Este es un descriptor ampliamente utilizado, principalmente en aplicaciones relacionadas con la musica, sin embargo, también se ha utilizado en el análisis de voz.\n",
    "- El vector de croma se calcula agrupando los coeficientes espectrales de un marco en 12 contenedores representando las 12 clases de tono moderado de la música de tipo occidental.\n",
    "- https://en.wikipedia.org/wiki/Chromatic_scale\n",
    "### 34 Desviacion Standar del vector cromatico\n",
    "\n",
    "- La desviacion estandar del vector cromatico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Frequency-domain audio features \"\"\"\n",
    "\n",
    "\n",
    "def stSpectralCentroidAndSpread(X, fs):\n",
    "    \"\"\"Computes spectral centroid of frame (given abs(FFT))\"\"\"\n",
    "    ind = (numpy.arange(1, len(X) + 1)) * (fs/(2.0 * len(X)))\n",
    "\n",
    "    Xt = X.copy()\n",
    "    Xt = Xt / Xt.max()\n",
    "    NUM = numpy.sum(ind * Xt)\n",
    "    DEN = numpy.sum(Xt) + numpy.finfo(float).eps\n",
    "\n",
    "    # Centroid:\n",
    "    C = (NUM / DEN)\n",
    "\n",
    "    # Spread:\n",
    "    S = numpy.sqrt(numpy.sum(((ind - C) ** 2) * Xt) / DEN)\n",
    "\n",
    "    # Normalize:\n",
    "    C = C / (fs / 2.0)\n",
    "    S = S / (fs / 2.0)\n",
    "\n",
    "    return (C, S)\n",
    "\n",
    "\n",
    "def stSpectralEntropy(X, numOfShortBlocks=10):\n",
    "    \"\"\"Computes the spectral entropy\"\"\"\n",
    "    L = len(X)                         # number of frame samples\n",
    "    Eol = numpy.sum(X ** 2)            # total spectral energy\n",
    "\n",
    "    subWinLength = int(numpy.floor(L / numOfShortBlocks))   # length of sub-frame\n",
    "    if L != subWinLength * numOfShortBlocks:\n",
    "        X = X[0:subWinLength * numOfShortBlocks]\n",
    "\n",
    "    subWindows = X.reshape(subWinLength, numOfShortBlocks, order='F').copy()  # define sub-frames (using matrix reshape)\n",
    "    s = numpy.sum(subWindows ** 2, axis=0) / (Eol + numpy.finfo(float).eps)                      # compute spectral sub-energies\n",
    "    En = -numpy.sum(s*numpy.log2(s + numpy.finfo(float).eps))                                    # compute spectral entropy\n",
    "\n",
    "    return En\n",
    "\n",
    "\n",
    "def stSpectralFlux(X, Xprev):\n",
    "    \"\"\"\n",
    "    Computes the spectral flux feature of the current frame\n",
    "    ARGUMENTS:\n",
    "        X:        the abs(fft) of the current frame\n",
    "        Xpre:        the abs(fft) of the previous frame\n",
    "    \"\"\"\n",
    "    # compute the spectral flux as the sum of square distances:\n",
    "    sumX = numpy.sum(X + numpy.finfo(float).eps)\n",
    "    sumPrevX = numpy.sum(Xprev + numpy.finfo(float).eps)\n",
    "    F = numpy.sum((X / sumX - Xprev/sumPrevX) ** 2)\n",
    "\n",
    "    return F\n",
    "\n",
    "\n",
    "def stSpectralRollOff(X, c, fs):\n",
    "    \"\"\"Computes spectral roll-off\"\"\"\n",
    "    totalEnergy = numpy.sum(X ** 2)\n",
    "    fftLength = len(X)\n",
    "    Thres = c*totalEnergy\n",
    "    # Ffind the spectral rolloff as the frequency position where the respective spectral energy is equal to c*totalEnergy\n",
    "    CumSum = numpy.cumsum(X ** 2) + eps\n",
    "    [a, ] = numpy.nonzero(CumSum > Thres)\n",
    "    if len(a) > 0:\n",
    "        mC = numpy.float64(a[0]) / (float(fftLength))\n",
    "    else:\n",
    "        mC = 0.0\n",
    "    return (mC)\n",
    "\n",
    "\n",
    "def stHarmonic(frame, fs):\n",
    "    \"\"\"\n",
    "    Computes harmonic ratio and pitch\n",
    "    \"\"\"\n",
    "    M = numpy.round(0.016 * fs) - 1\n",
    "    R = numpy.correlate(frame, frame, mode='full')\n",
    "\n",
    "    g = R[len(frame)-1]\n",
    "    R = R[len(frame):-1]\n",
    "\n",
    "    # estimate m0 (as the first zero crossing of R)\n",
    "    [a, ] = numpy.nonzero(numpy.diff(numpy.sign(R)))\n",
    "\n",
    "    if len(a) == 0:\n",
    "        m0 = len(R)-1\n",
    "    else:\n",
    "        m0 = a[0]\n",
    "    if M > len(R):\n",
    "        M = len(R) - 1\n",
    "\n",
    "    M = int(M)\n",
    "    Gamma = numpy.zeros((M), dtype=numpy.float64)\n",
    "    CSum = numpy.cumsum(frame ** 2)\n",
    "    Gamma[m0:M] = R[m0:M] / (numpy.sqrt((g * CSum[M:m0:-1])) + eps)\n",
    "\n",
    "    ZCR = stZCR(Gamma)\n",
    "\n",
    "    if ZCR > 0.15:\n",
    "        HR = 0.0\n",
    "        f0 = 0.0\n",
    "    else:\n",
    "        if len(Gamma) == 0:\n",
    "            HR = 1.0\n",
    "            blag = 0.0\n",
    "            Gamma = numpy.zeros((M), dtype=numpy.float64)\n",
    "        else:\n",
    "            HR = numpy.max(Gamma)\n",
    "            blag = numpy.argmax(Gamma)\n",
    "\n",
    "        # Get fundamental frequency:\n",
    "        f0 = fs / (blag + eps)\n",
    "        if f0 > 5000:\n",
    "            f0 = 0.0\n",
    "        if HR < 0.1:\n",
    "            f0 = 0.0\n",
    "\n",
    "    return (HR, f0)\n",
    "\n",
    "\n",
    "def mfccInitFilterBanks(fs, nfft):\n",
    "    \"\"\"\n",
    "    Computes the triangular filterbank for MFCC computation (used in the stFeatureExtraction function before the stMFCC function call)\n",
    "    This function is taken from the scikits.talkbox library (MIT Licence):\n",
    "    https://pypi.python.org/pypi/scikits.talkbox\n",
    "    \"\"\"\n",
    "\n",
    "    # filter bank params:\n",
    "    lowfreq = 133.33\n",
    "    linsc = 200/3.\n",
    "    logsc = 1.0711703\n",
    "    numLinFiltTotal = 13\n",
    "    numLogFilt = 27\n",
    "\n",
    "    if fs < 8000:\n",
    "        nlogfil = 5\n",
    "\n",
    "    # Total number of filters\n",
    "    nFiltTotal = numLinFiltTotal + numLogFilt\n",
    "\n",
    "    # Compute frequency points of the triangle:\n",
    "    freqs = numpy.zeros(nFiltTotal+2)\n",
    "    freqs[:numLinFiltTotal] = lowfreq + numpy.arange(numLinFiltTotal) * linsc\n",
    "    freqs[numLinFiltTotal:] = freqs[numLinFiltTotal-1] * logsc ** numpy.arange(1, numLogFilt + 3)\n",
    "    heights = 2./(freqs[2:] - freqs[0:-2])\n",
    "\n",
    "    # Compute filterbank coeff (in fft domain, in bins)\n",
    "    fbank = numpy.zeros((nFiltTotal, int(nfft) ) ) \n",
    "    nfreqs = numpy.arange(nfft) / (1. * nfft) * fs\n",
    "\n",
    "    for i in range(nFiltTotal):\n",
    "        lowTrFreq = freqs[i]\n",
    "        cenTrFreq = freqs[i+1]\n",
    "        highTrFreq = freqs[i+2]\n",
    "\n",
    "        lid = numpy.arange(numpy.floor(lowTrFreq * nfft / fs) + 1, numpy.floor(cenTrFreq * nfft / fs) + 1, dtype=numpy.int)\n",
    "        lslope = heights[i] / (cenTrFreq - lowTrFreq)\n",
    "        rid = numpy.arange(numpy.floor(cenTrFreq * nfft / fs) + 1, numpy.floor(highTrFreq * nfft / fs) + 1, dtype=numpy.int)\n",
    "        rslope = heights[i] / (highTrFreq - cenTrFreq)\n",
    "        fbank[i][lid] = lslope * (nfreqs[lid] - lowTrFreq)\n",
    "        fbank[i][rid] = rslope * (highTrFreq - nfreqs[rid])\n",
    "\n",
    "    return fbank, freqs\n",
    "\n",
    "\n",
    "def stMFCC(X, fbank, nceps):\n",
    "    \"\"\"\n",
    "    Computes the MFCCs of a frame, given the fft mag\n",
    "\n",
    "    ARGUMENTS:\n",
    "        X:        fft magnitude abs(FFT)\n",
    "        fbank:    filter bank (see mfccInitFilterBanks)\n",
    "    RETURN\n",
    "        ceps:     MFCCs (13 element vector)\n",
    "\n",
    "    Note:    MFCC calculation is, in general, taken from the scikits.talkbox library (MIT Licence),\n",
    "    #    with a small number of modifications to make it more compact and suitable for the pyAudioAnalysis Lib\n",
    "    \"\"\"\n",
    "\n",
    "    mspec = numpy.log10(numpy.dot(X, fbank.T)+eps)\n",
    "    ceps = dct(mspec, type=2, norm='ortho', axis=-1)[:nceps]\n",
    "    return ceps\n",
    "\n",
    "\n",
    "def stChromaFeaturesInit(nfft, fs):\n",
    "    \"\"\"\n",
    "    This function initializes the chroma matrices used in the calculation of the chroma features\n",
    "    \"\"\"\n",
    "    freqs = numpy.array([((f + 1) * fs) / (2 * int(nfft)) for f in range(int(nfft))])    \n",
    "    Cp = 27.50    \n",
    "    nChroma = numpy.round(12.0 * numpy.log2(freqs / Cp)).astype(int)\n",
    "\n",
    "    nFreqsPerChroma = numpy.zeros((nChroma.shape[0], ))\n",
    "\n",
    "    uChroma = numpy.unique(nChroma)\n",
    "    for u in uChroma:\n",
    "        idx = numpy.nonzero(nChroma == u)\n",
    "        nFreqsPerChroma[idx] = idx[0].shape\n",
    "    \n",
    "    return nChroma, nFreqsPerChroma\n",
    "\n",
    "\n",
    "def stChromaFeatures(X, fs, nChroma, nFreqsPerChroma):\n",
    "    #TODO: 1 complexity\n",
    "    #TODO: 2 bug with large windows\n",
    "\n",
    "    chromaNames = ['A', 'A#', 'B', 'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#']\n",
    "    spec = X**2    \n",
    "    if nChroma.max()<nChroma.shape[0]:        \n",
    "        C = numpy.zeros((nChroma.shape[0],))\n",
    "        C[nChroma] = spec\n",
    "        C /= nFreqsPerChroma[nChroma]\n",
    "    else:        \n",
    "        I = numpy.nonzero(nChroma>nChroma.shape[0])[0][0]        \n",
    "        C = numpy.zeros((nChroma.shape[0],))\n",
    "        C[nChroma[0:I-1]] = spec            \n",
    "        C /= nFreqsPerChroma\n",
    "    finalC = numpy.zeros((12, 1))\n",
    "    newD = int(numpy.ceil(C.shape[0] / 12.0) * 12)\n",
    "    C2 = numpy.zeros((newD, ))\n",
    "    C2[0:C.shape[0]] = C\n",
    "    C2 = C2.reshape(C2.shape[0]//12, 12)\n",
    "    #for i in range(12):\n",
    "    #    finalC[i] = numpy.sum(C[i:C.shape[0]:12])\n",
    "    finalC = numpy.matrix(numpy.sum(C2, axis=0)).T\n",
    "    finalC /= spec.sum()\n",
    "\n",
    "#    ax = plt.gca()\n",
    "#    plt.hold(False)\n",
    "#    plt.plot(finalC)\n",
    "#    ax.set_xticks(range(len(chromaNames)))\n",
    "#    ax.set_xticklabels(chromaNames)\n",
    "#    xaxis = numpy.arange(0, 0.02, 0.01);\n",
    "#    ax.set_yticks(range(len(xaxis)))\n",
    "#    ax.set_yticklabels(xaxis)\n",
    "#    plt.show(block=False)\n",
    "#    plt.draw()\n",
    "\n",
    "    return chromaNames, finalC\n",
    "\n",
    "\n",
    "def stChromagram(signal, Fs, Win, Step, PLOT=False):\n",
    "    \"\"\"\n",
    "    Short-term FFT mag for spectogram estimation:\n",
    "    Returns:\n",
    "        a numpy array (nFFT x numOfShortTermWindows)\n",
    "    ARGUMENTS:\n",
    "        signal:      the input signal samples\n",
    "        Fs:          the sampling freq (in Hz)\n",
    "        Win:         the short-term window size (in samples)\n",
    "        Step:        the short-term window step (in samples)\n",
    "        PLOT:        flag, 1 if results are to be ploted\n",
    "    RETURNS:\n",
    "    \"\"\"\n",
    "    Win = int(Win)\n",
    "    Step = int(Step)\n",
    "    signal = numpy.double(signal)\n",
    "    signal = signal / (2.0 ** 15)\n",
    "    DC = signal.mean()\n",
    "    MAX = (numpy.abs(signal)).max()\n",
    "    signal = (signal - DC) / (MAX - DC)\n",
    "\n",
    "    N = len(signal)        # total number of signals\n",
    "    curPos = 0\n",
    "    countFrames = 0\n",
    "    nfft = int(Win / 2)\n",
    "    nChroma, nFreqsPerChroma = stChromaFeaturesInit(nfft, Fs)\n",
    "    chromaGram = numpy.array([], dtype=numpy.float64)\n",
    "\n",
    "    while (curPos + Win - 1 < N):\n",
    "        countFrames += 1\n",
    "        x = signal[curPos:curPos + Win]\n",
    "        curPos = curPos + Step\n",
    "        X = abs(fft(x))\n",
    "        X = X[0:nfft]\n",
    "        X = X / len(X)\n",
    "        chromaNames, C = stChromaFeatures(X, Fs, nChroma, nFreqsPerChroma)\n",
    "        C = C[:, 0]\n",
    "        if countFrames == 1:\n",
    "            chromaGram = C.T\n",
    "        else:\n",
    "            chromaGram = numpy.vstack((chromaGram, C.T))\n",
    "    FreqAxis = chromaNames\n",
    "    TimeAxis = [(t * Step) / Fs for t in range(chromaGram.shape[0])]\n",
    "\n",
    "    if (PLOT):\n",
    "        fig, ax = plt.subplots()\n",
    "        chromaGramToPlot = chromaGram.transpose()[::-1, :]\n",
    "        Ratio = chromaGramToPlot.shape[1] / (3*chromaGramToPlot.shape[0])        \n",
    "        if Ratio < 1:\n",
    "            Ratio = 1\n",
    "        chromaGramToPlot = numpy.repeat(chromaGramToPlot, Ratio, axis=0)\n",
    "        imgplot = plt.imshow(chromaGramToPlot)\n",
    "        Fstep = int(nfft / 5.0)\n",
    "#        FreqTicks = range(0, int(nfft) + Fstep, Fstep)\n",
    "#        FreqTicksLabels = [str(Fs/2-int((f*Fs) / (2*nfft))) for f in FreqTicks]\n",
    "        ax.set_yticks(range(Ratio / 2, len(FreqAxis) * Ratio, Ratio))\n",
    "        ax.set_yticklabels(FreqAxis[::-1])\n",
    "        TStep = countFrames / 3\n",
    "        TimeTicks = range(0, countFrames, TStep)\n",
    "        TimeTicksLabels = ['%.2f' % (float(t * Step) / Fs) for t in TimeTicks]\n",
    "        ax.set_xticks(TimeTicks)\n",
    "        ax.set_xticklabels(TimeTicksLabels)\n",
    "        ax.set_xlabel('time (secs)')\n",
    "        imgplot.set_cmap('jet')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    return (chromaGram, TimeAxis, FreqAxis)\n",
    "\n",
    "\n",
    "def phormants(x, Fs):\n",
    "    N = len(x)\n",
    "    w = numpy.hamming(N)\n",
    "\n",
    "    # Apply window and high pass filter.\n",
    "    x1 = x * w   \n",
    "    x1 = lfilter([1], [1., 0.63], x1)\n",
    "    \n",
    "    # Get LPC.    \n",
    "    ncoeff = 2 + Fs / 1000\n",
    "    A, e, k = lpc(x1, ncoeff)    \n",
    "    #A, e, k = lpc(x1, 8)\n",
    "\n",
    "    # Get roots.\n",
    "    rts = numpy.roots(A)\n",
    "    rts = [r for r in rts if numpy.imag(r) >= 0]\n",
    "\n",
    "    # Get angles.\n",
    "    angz = numpy.arctan2(numpy.imag(rts), numpy.real(rts))\n",
    "\n",
    "    # Get frequencies.    \n",
    "    frqs = sorted(angz * (Fs / (2 * math.pi)))\n",
    "\n",
    "    return frqs\n",
    "def beatExtraction(stFeatures, winSize, PLOT=False):\n",
    "    \"\"\"\n",
    "    This function extracts an estimate of the beat rate for a musical signal.\n",
    "    ARGUMENTS:\n",
    "     - stFeatures:     a numpy array (numOfFeatures x numOfShortTermWindows)\n",
    "     - winSize:        window size in seconds\n",
    "    RETURNS:\n",
    "     - BPM:            estimates of beats per minute\n",
    "     - Ratio:          a confidence measure\n",
    "    \"\"\"\n",
    "\n",
    "    # Features that are related to the beat tracking task:\n",
    "    toWatch = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "\n",
    "    maxBeatTime = int(round(2.0 / winSize))\n",
    "    HistAll = numpy.zeros((maxBeatTime,))\n",
    "    for ii, i in enumerate(toWatch):                                        # for each feature\n",
    "        DifThres = 2.0 * (numpy.abs(stFeatures[i, 0:-1] - stFeatures[i, 1::])).mean()    # dif threshold (3 x Mean of Difs)\n",
    "        if DifThres<=0:\n",
    "            DifThres = 0.0000000000000001        \n",
    "        [pos1, _] = utilities.peakdet(stFeatures[i, :], DifThres)           # detect local maxima\n",
    "        posDifs = []                                                        # compute histograms of local maxima changes\n",
    "        for j in range(len(pos1)-1):\n",
    "            posDifs.append(pos1[j+1]-pos1[j])\n",
    "        [HistTimes, HistEdges] = numpy.histogram(posDifs, numpy.arange(0.5, maxBeatTime + 1.5))\n",
    "        HistCenters = (HistEdges[0:-1] + HistEdges[1::]) / 2.0\n",
    "        HistTimes = HistTimes.astype(float) / stFeatures.shape[1]\n",
    "        HistAll += HistTimes\n",
    "        if PLOT:\n",
    "            plt.subplot(9, 2, ii + 1)\n",
    "            plt.plot(stFeatures[i, :], 'k')\n",
    "            for k in pos1:\n",
    "                plt.plot(k, stFeatures[i, k], 'k*')\n",
    "            f1 = plt.gca()\n",
    "            f1.axes.get_xaxis().set_ticks([])\n",
    "            f1.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "    if PLOT:\n",
    "        plt.show(block=False)\n",
    "        plt.figure()\n",
    "\n",
    "    # Get beat as the argmax of the agregated histogram:\n",
    "    I = numpy.argmax(HistAll)\n",
    "    BPMs = 60 / (HistCenters * winSize)\n",
    "    BPM = BPMs[I]\n",
    "    # ... and the beat ratio:\n",
    "    Ratio = HistAll[I] / HistAll.sum()\n",
    "\n",
    "    if PLOT:\n",
    "        # filter out >500 beats from plotting:\n",
    "        HistAll = HistAll[BPMs < 500]\n",
    "        BPMs = BPMs[BPMs < 500]\n",
    "\n",
    "        plt.plot(BPMs, HistAll, 'k')\n",
    "        plt.xlabel('Beats per minute')\n",
    "        plt.ylabel('Freq Count')\n",
    "        plt.show(block=True)\n",
    "\n",
    "    return BPM, Ratio\n",
    "\n",
    "\n",
    "def stSpectogram(signal, Fs, Win, Step, PLOT=False):\n",
    "    \"\"\"\n",
    "    Short-term FFT mag for spectogram estimation:\n",
    "    Returns:\n",
    "        a numpy array (nFFT x numOfShortTermWindows)\n",
    "    ARGUMENTS:\n",
    "        signal:      the input signal samples\n",
    "        Fs:          the sampling freq (in Hz)\n",
    "        Win:         the short-term window size (in samples)\n",
    "        Step:        the short-term window step (in samples)\n",
    "        PLOT:        flag, 1 if results are to be ploted\n",
    "    RETURNS:\n",
    "    \"\"\"\n",
    "    Win = int(Win)\n",
    "    Step = int(Step)\n",
    "    signal = numpy.double(signal)\n",
    "    signal = signal / (2.0 ** 15)\n",
    "    DC = signal.mean()\n",
    "    MAX = (numpy.abs(signal)).max()\n",
    "    signal = (signal - DC) / (MAX - DC)\n",
    "\n",
    "    N = len(signal)        # total number of signals\n",
    "    curPos = 0\n",
    "    countFrames = 0\n",
    "    nfft = int(Win / 2)\n",
    "    specgram = numpy.array([], dtype=numpy.float64)\n",
    "\n",
    "    while (curPos + Win - 1 < N):\n",
    "        countFrames += 1\n",
    "        x = signal[curPos:curPos+Win]\n",
    "        curPos = curPos + Step\n",
    "        X = abs(fft(x))\n",
    "        X = X[0:nfft]\n",
    "        X = X / len(X)\n",
    "\n",
    "        if countFrames == 1:\n",
    "            specgram = X ** 2\n",
    "        else:\n",
    "            specgram = numpy.vstack((specgram, X))\n",
    "\n",
    "    FreqAxis = [((f + 1) * Fs) / (2 * nfft) for f in range(specgram.shape[1])]\n",
    "    TimeAxis = [(t * Step) / Fs for t in range(specgram.shape[0])]\n",
    "\n",
    "    if (PLOT):\n",
    "        fig, ax = plt.subplots()\n",
    "        imgplot = plt.imshow(specgram.transpose()[::-1, :])\n",
    "        Fstep = int(nfft / 5.0)\n",
    "        FreqTicks = range(0, int(nfft) + Fstep, Fstep)\n",
    "        FreqTicksLabels = [str(Fs / 2 - int((f * Fs) / (2 * nfft))) for f in FreqTicks]\n",
    "        ax.set_yticks(FreqTicks)\n",
    "        ax.set_yticklabels(FreqTicksLabels)\n",
    "        TStep = countFrames/3\n",
    "        TimeTicks = range(0, countFrames, TStep)\n",
    "        TimeTicksLabels = ['%.2f' % (float(t * Step) / Fs) for t in TimeTicks]\n",
    "        ax.set_xticks(TimeTicks)\n",
    "        ax.set_xticklabels(TimeTicksLabels)\n",
    "        ax.set_xlabel('time (secs)')\n",
    "        ax.set_ylabel('freq (Hz)')\n",
    "        imgplot.set_cmap('jet')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    return (specgram, TimeAxis, FreqAxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Windowing and feature extraction \"\"\"\n",
    "\n",
    "\n",
    "def stFeatureExtraction(signal, Fs, Win, Step):\n",
    "    \"\"\"\n",
    "    This function implements the shor-term windowing process. For each short-term window a set of features is extracted.\n",
    "    This results to a sequence of feature vectors, stored in a numpy matrix.\n",
    "\n",
    "    ARGUMENTS\n",
    "        signal:       the input signal samples\n",
    "        Fs:           the sampling freq (in Hz)\n",
    "        Win:          the short-term window size (in samples)\n",
    "        Step:         the short-term window step (in samples)\n",
    "    RETURNS\n",
    "        stFeatures:   a numpy array (numOfFeatures x numOfShortTermWindows)\n",
    "    \"\"\"\n",
    "\n",
    "    Win = int(Win)\n",
    "    Step = int(Step)\n",
    "\n",
    "    # Signal normalization\n",
    "    signal = numpy.double(signal)\n",
    "\n",
    "    signal = signal / (2.0 ** 15)\n",
    "    DC = signal.mean()\n",
    "    MAX = (numpy.abs(signal)).max()\n",
    "    signal = (signal - DC) / (MAX + 0.0000000001)\n",
    "\n",
    "    N = len(signal)                                # total number of samples\n",
    "    curPos = 0\n",
    "    countFrames = 0\n",
    "    nFFT = Win / 2\n",
    "\n",
    "    [fbank, freqs] = mfccInitFilterBanks(Fs, nFFT)                # compute the triangular filter banks used in the mfcc calculation\n",
    "    nChroma, nFreqsPerChroma = stChromaFeaturesInit(nFFT, Fs)\n",
    "\n",
    "    numOfTimeSpectralFeatures = 8\n",
    "    numOfHarmonicFeatures = 0\n",
    "    nceps = 13\n",
    "    numOfChromaFeatures = 13\n",
    "    totalNumOfFeatures = numOfTimeSpectralFeatures + nceps + numOfHarmonicFeatures + numOfChromaFeatures\n",
    "#    totalNumOfFeatures = numOfTimeSpectralFeatures + nceps + numOfHarmonicFeatures\n",
    "\n",
    "    stFeatures = []\n",
    "    while (curPos + Win - 1 < N):                        # for each short-term window until the end of signal\n",
    "        countFrames += 1\n",
    "        x = signal[curPos:curPos+Win]                    # get current window\n",
    "        curPos = curPos + Step                           # update window position\n",
    "        X = abs(fft(x))                                  # get fft magnitude\n",
    "        X = X[0:int(nFFT)]                                    # normalize fft\n",
    "        X = X / len(X)\n",
    "        if countFrames == 1:\n",
    "            Xprev = X.copy()                             # keep previous fft mag (used in spectral flux)\n",
    "        curFV = numpy.zeros((totalNumOfFeatures, 1))\n",
    "        curFV[0] = stZCR(x)                              # zero crossing rate\n",
    "        curFV[1] = stEnergy(x)                           # short-term energy\n",
    "        curFV[2] = stEnergyEntropy(x)                    # short-term entropy of energy\n",
    "        curFV[3] = stSpectralCentroidAndSpread(X, Fs)[0] # spectral centroid \n",
    "        curFV[4] = stHarmonic(x,Fs)[1]                   # pitch\n",
    "        curFV[5] = stSpectralEntropy(X)                  # spectral entropy\n",
    "        curFV[6] = stSpectralFlux(X, Xprev)              # spectral flux\n",
    "        curFV[7] = stSpectralRollOff(X, 0.90, Fs)        # spectral rolloff\n",
    "        curFV[numOfTimeSpectralFeatures:numOfTimeSpectralFeatures+nceps, 0] = stMFCC(X, fbank, nceps).copy()    # MFCCs\n",
    "\n",
    "        chromaNames, chromaF = stChromaFeatures(X, Fs, nChroma, nFreqsPerChroma)\n",
    "        curFV[numOfTimeSpectralFeatures + nceps: numOfTimeSpectralFeatures + nceps + numOfChromaFeatures - 1] = chromaF\n",
    "        curFV[numOfTimeSpectralFeatures + nceps + numOfChromaFeatures - 1] = chromaF.std()\n",
    "        stFeatures.append(curFV)\n",
    "        # delta features\n",
    "        '''\n",
    "        if countFrames>1:\n",
    "            delta = curFV - prevFV\n",
    "            curFVFinal = numpy.concatenate((curFV, delta))            \n",
    "        else:\n",
    "            curFVFinal = numpy.concatenate((curFV, curFV))\n",
    "        prevFV = curFV\n",
    "        stFeatures.append(curFVFinal)        \n",
    "        '''\n",
    "        # end of delta\n",
    "        Xprev = X.copy()\n",
    "\n",
    "    stFeatures = numpy.concatenate(stFeatures, 1)\n",
    "    return stFeatures\n",
    "\n",
    "\n",
    "def mtFeatureExtraction(signal, Fs, mtWin, mtStep, stWin, stStep):\n",
    "    \"\"\"\n",
    "    Mid-term feature extraction\n",
    "    \"\"\"\n",
    "\n",
    "    mtWinRatio = int(round(mtWin / stStep))\n",
    "    mtStepRatio = int(round(mtStep / stStep))\n",
    "\n",
    "    mtFeatures = []\n",
    "\n",
    "    stFeatures = stFeatureExtraction(signal, Fs, stWin, stStep)\n",
    "    numOfFeatures = len(stFeatures)\n",
    "    numOfStatistics = 2\n",
    "\n",
    "    mtFeatures = []\n",
    "    #for i in range(numOfStatistics * numOfFeatures + 1):\n",
    "    for i in range(numOfStatistics * numOfFeatures):\n",
    "        mtFeatures.append([])\n",
    "\n",
    "    for i in range(numOfFeatures):        # for each of the short-term features:\n",
    "        curPos = 0\n",
    "        N = len(stFeatures[i])\n",
    "        while (curPos < N):\n",
    "            N1 = curPos\n",
    "            N2 = curPos + mtWinRatio\n",
    "            if N2 > N:\n",
    "                N2 = N\n",
    "            curStFeatures = stFeatures[i][N1:N2]\n",
    "\n",
    "            mtFeatures[i].append(numpy.mean(curStFeatures))\n",
    "            mtFeatures[i+numOfFeatures].append(numpy.std(curStFeatures))\n",
    "            #mtFeatures[i+2*numOfFeatures].append(numpy.std(curStFeatures) / (numpy.mean(curStFeatures)+0.00000010))\n",
    "            curPos += mtStepRatio\n",
    "\n",
    "    return numpy.array(mtFeatures), stFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Feature Extraction Wrappers\n",
    "\n",
    " - The first two feature extraction wrappers are used to extract long-term averaged\n",
    "   audio features for a list of WAV files stored in a given category.\n",
    "   It is important to note that, one single feature is extracted per WAV file (not the whole sequence of feature vectors)\n",
    "\n",
    " \"\"\"\n",
    "\n",
    "\n",
    "def dirWavFeatureExtraction(dirName, mtWin, mtStep, stWin, stStep, computeBEAT=False):\n",
    "    \"\"\"\n",
    "    This function extracts the mid-term features of the WAVE files of a particular folder.\n",
    "\n",
    "    The resulting feature vector is extracted by long-term averaging the mid-term features.\n",
    "    Therefore ONE FEATURE VECTOR is extracted for each WAV file.\n",
    "\n",
    "    ARGUMENTS:\n",
    "        - dirName:        the path of the WAVE directory\n",
    "        - mtWin, mtStep:    mid-term window and step (in seconds)\n",
    "        - stWin, stStep:    short-term window and step (in seconds)\n",
    "    \"\"\"\n",
    "\n",
    "    allMtFeatures = numpy.array([])\n",
    "    processingTimes = []\n",
    "\n",
    "    types = ('*.wav', '*.aif',  '*.aiff', '*.mp3','*.au')\n",
    "    wavFilesList = []\n",
    "    for files in types:\n",
    "        wavFilesList.extend(glob.glob(os.path.join(dirName, files)))\n",
    "\n",
    "    wavFilesList = sorted(wavFilesList)    \n",
    "    wavFilesList2 = []\n",
    "    for i, wavFile in enumerate(wavFilesList):        \n",
    "        print (\"Analyzing file {0:d} of {1:d}: {2}\".format(i+1, len(wavFilesList), wavFile.encode('utf-8')))\n",
    "        if os.stat(wavFile).st_size == 0:\n",
    "            print (\"   (EMPTY FILE -- SKIPPING)\")\n",
    "            continue        \n",
    "        [Fs, x] = audioBasicIO.readAudioFile(wavFile)            # read file    \n",
    "        if isinstance(x, int):\n",
    "            continue        \n",
    "\n",
    "        t1 = time.clock()        \n",
    "        x = audioBasicIO.stereo2mono(x)                          # convert stereo to mono                \n",
    "        if x.shape[0]<float(Fs)/10:\n",
    "            print (\"  (AUDIO FILE TOO SMALL - SKIPPING)\")\n",
    "            continue\n",
    "        wavFilesList2.append(wavFile)\n",
    "        if computeBEAT:                                          # mid-term feature extraction for current file\n",
    "            [MidTermFeatures, stFeatures] = mtFeatureExtraction(x, Fs, round(mtWin * Fs), round(mtStep * Fs), round(Fs * stWin), round(Fs * stStep))\n",
    "            [beat, beatConf] = beatExtraction(stFeatures, stStep)\n",
    "        else:\n",
    "            [MidTermFeatures, _] = mtFeatureExtraction(x, Fs, round(mtWin * Fs), round(mtStep * Fs), round(Fs * stWin), round(Fs * stStep))\n",
    "\n",
    "        MidTermFeatures = numpy.transpose(MidTermFeatures)\n",
    "        MidTermFeatures = MidTermFeatures.mean(axis=0)         # long term averaging of mid-term statistics\n",
    "        if (not numpy.isnan(MidTermFeatures).any()) and (not numpy.isinf(MidTermFeatures).any()):            \n",
    "            if computeBEAT:\n",
    "                MidTermFeatures = numpy.append(MidTermFeatures, beat)\n",
    "                MidTermFeatures = numpy.append(MidTermFeatures, beatConf)\n",
    "            if len(allMtFeatures) == 0:                              # append feature vector\n",
    "                allMtFeatures = MidTermFeatures\n",
    "            else:\n",
    "                allMtFeatures = numpy.vstack((allMtFeatures, MidTermFeatures))\n",
    "            t2 = time.clock()\n",
    "            duration = float(len(x)) / Fs\n",
    "            processingTimes.append((t2 - t1) / duration)\n",
    "    if len(processingTimes) > 0:\n",
    "        print (\"Feature extraction complexity ratio: {0:.1f} x realtime\".format((1.0 / numpy.mean(numpy.array(processingTimes)))))\n",
    "    return (allMtFeatures, wavFilesList2)\n",
    "\n",
    "\n",
    "def dirsWavFeatureExtraction(dirNames, mtWin, mtStep, stWin, stStep, computeBEAT=False):\n",
    "    '''\n",
    "    Same as dirWavFeatureExtraction, but instead of a single dir it takes a list of paths as input and returns a list of feature matrices.\n",
    "    EXAMPLE:\n",
    "    [features, classNames] =\n",
    "           a.dirsWavFeatureExtraction(['audioData/classSegmentsRec/noise','audioData/classSegmentsRec/speech',\n",
    "                                       'audioData/classSegmentsRec/brush-teeth','audioData/classSegmentsRec/shower'], 1, 1, 0.02, 0.02);\n",
    "\n",
    "    It can be used during the training process of a classification model ,\n",
    "    in order to get feature matrices from various audio classes (each stored in a seperate path)\n",
    "    '''\n",
    "\n",
    "    # feature extraction for each class:\n",
    "    features = []\n",
    "    classNames = []\n",
    "    fileNames = []\n",
    "    for i, d in enumerate(dirNames):\n",
    "        [f, fn] = dirWavFeatureExtraction(d, mtWin, mtStep, stWin, stStep,computeBEAT=computeBEAT)\n",
    "        if f.shape[0] > 0:       # if at least one audio file has been found in the provided folder:\n",
    "            features.append(f)\n",
    "            fileNames.append(fn)\n",
    "            if d[-1] == \"/\":\n",
    "                classNames.append(d.split(os.sep)[-2])\n",
    "            else:\n",
    "                classNames.append(d.split(os.sep)[-1])\n",
    "    return features, classNames, fileNames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file 1 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/0-0.wav'\n",
      "Analyzing file 2 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/0-1.wav'\n",
      "Analyzing file 3 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/0-2.wav'\n",
      "Analyzing file 4 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/1-5.wav'\n",
      "Analyzing file 5 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/1-6.wav'\n",
      "Analyzing file 6 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/4-14.wav'\n",
      "Analyzing file 7 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/4-15.wav'\n",
      "Analyzing file 8 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/4-16.wav'\n",
      "Analyzing file 9 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/4-17.wav'\n",
      "Analyzing file 10 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/4-18.wav'\n",
      "Analyzing file 11 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/6-26.wav'\n",
      "Analyzing file 12 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/6-27.wav'\n",
      "Analyzing file 13 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/6-28.wav'\n",
      "Analyzing file 14 of 14: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/anger/6-29.wav'\n",
      "Feature extraction complexity ratio: 20.7 x realtime\n",
      "Analyzing file 1 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/1-3.wav'\n",
      "Analyzing file 2 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/5-20.wav'\n",
      "Analyzing file 3 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/5-21.wav'\n",
      "Analyzing file 4 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/5-22.wav'\n",
      "Analyzing file 5 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/5-23.wav'\n",
      "Analyzing file 6 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/5-24.wav'\n",
      "Analyzing file 7 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/5-25.wav'\n",
      "Analyzing file 8 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-36.wav'\n",
      "Analyzing file 9 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-37.wav'\n",
      "Analyzing file 10 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-38.wav'\n",
      "Analyzing file 11 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-39.wav'\n",
      "Analyzing file 12 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-40.wav'\n",
      "Analyzing file 13 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-41.wav'\n",
      "Analyzing file 14 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-42.wav'\n",
      "Analyzing file 15 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/8-43.wav'\n",
      "Analyzing file 16 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/9-44.wav'\n",
      "Analyzing file 17 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/9-45.wav'\n",
      "Analyzing file 18 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/9-46.wav'\n",
      "Analyzing file 19 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/9-47.wav'\n",
      "Analyzing file 20 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/9-48.wav'\n",
      "Analyzing file 21 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/9-49.wav'\n",
      "Analyzing file 22 of 22: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/sadness/9-50.wav'\n",
      "Feature extraction complexity ratio: 22.0 x realtime\n",
      "Analyzing file 1 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/12-66.wav'\n",
      "Analyzing file 2 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/12-67.wav'\n",
      "Analyzing file 3 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/12-68.wav'\n",
      "Analyzing file 4 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/12-69.wav'\n",
      "Analyzing file 5 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/12-70.wav'\n",
      "Analyzing file 6 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/12-71.wav'\n",
      "Analyzing file 7 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/2-6.wav'\n",
      "Analyzing file 8 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/3-12.wav'\n",
      "Analyzing file 9 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/3-13.wav'\n",
      "Analyzing file 10 of 10: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/disgust/3-7.wav'\n",
      "Feature extraction complexity ratio: 22.6 x realtime\n",
      "Analyzing file 1 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-51.wav'\n",
      "Analyzing file 2 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-52.wav'\n",
      "Analyzing file 3 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-53.wav'\n",
      "Analyzing file 4 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-54.wav'\n",
      "Analyzing file 5 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-55.wav'\n",
      "Analyzing file 6 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-56.wav'\n",
      "Analyzing file 7 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-57.wav'\n",
      "Analyzing file 8 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/10-58.wav'\n",
      "Analyzing file 9 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-59.wav'\n",
      "Analyzing file 10 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-60.wav'\n",
      "Analyzing file 11 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-61.wav'\n",
      "Analyzing file 12 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-62.wav'\n",
      "Analyzing file 13 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-63.wav'\n",
      "Analyzing file 14 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-64.wav'\n",
      "Analyzing file 15 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-65.wav'\n",
      "Analyzing file 16 of 16: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/fear/11-66.wav'\n",
      "Feature extraction complexity ratio: 22.4 x realtime\n",
      "Analyzing file 1 of 7: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/happiness/3-8.wav'\n",
      "Analyzing file 2 of 7: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/happiness/5-19.wav'\n",
      "Analyzing file 3 of 7: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/happiness/7-30.wav'\n",
      "Analyzing file 4 of 7: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/happiness/7-31.wav'\n",
      "Analyzing file 5 of 7: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/happiness/7-32.wav'\n",
      "Analyzing file 6 of 7: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/happiness/7-33.wav'\n",
      "Analyzing file 7 of 7: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/happiness/7-35.wav'\n",
      "Feature extraction complexity ratio: 22.3 x realtime\n",
      "Analyzing file 1 of 3: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/surprise/1-7.wav'\n",
      "Analyzing file 2 of 3: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/surprise/3-10.wav'\n",
      "Analyzing file 3 of 3: b'/home/neriomoran/Escritorio/ProyectoSeminario/ProyectoFinal/YoutubeDownload/surprise/3-11.wav'\n",
      "Feature extraction complexity ratio: 21.6 x realtime\n",
      "['anger', 'sadness', 'disgust', 'fear', 'happiness', 'surprise']\n",
      "Conversion de lista de matrices a una sola matriz\n",
      "14\n",
      "22\n",
      "10\n",
      "16\n",
      "7\n",
      "3\n",
      "                   ZCR                Energy    Entropy Of Enery  \\\n",
      "0  0.14080100125156444  0.034542248307072136   2.998446164434176   \n",
      "1    0.143054915135147  0.033249171181203165  2.9919231542880613   \n",
      "2  0.13201962980040843   0.03979424038894387  2.9914091702618837   \n",
      "3   0.1489896910611949   0.02924640746399027  3.0958750023817467   \n",
      "4  0.14401335002085938  0.033666444404778346  3.1230974249249237   \n",
      "\n",
      "     Spectral Centroid               Pitch    Spectral Entropy  \\\n",
      "0  0.21973947489847026  145.96764211997052   1.269594864597256   \n",
      "1  0.22425063033530446  139.08919393694177    1.37299326041848   \n",
      "2  0.20918159316465182  125.16108221747898  1.2124625225521766   \n",
      "3  0.21458598196656686   95.73136317025704    1.44022955587356   \n",
      "4    0.215850220751881  155.73791705374086  1.3572178820798353   \n",
      "\n",
      "          Spectral Flux    Spectral Roll-off                MFCC1  \\\n",
      "0  0.012848450679206128  0.23872916666666666  -24.386966974666564   \n",
      "1  0.011735784277001097  0.25029166666666663  -23.979904017291044   \n",
      "2  0.013575947919123452  0.21129605263157894  -24.659123011761228   \n",
      "3  0.009390616212437714   0.2477598684210526  -23.407225251181544   \n",
      "4  0.009990597754643211  0.22191666666666665  -23.160478544553253   \n",
      "\n",
      "                MFCC2   ...                   std26                 std27  \\\n",
      "0  0.5377951982247611   ...    0.015260583544442109   0.03308879515521928   \n",
      "1  0.5278398500546307   ...     0.02795457925942678   0.02506636844925786   \n",
      "2  1.0016640592683288   ...    0.017757099879613877  0.033222901218101356   \n",
      "3  0.6389770189380657   ...    0.011518839725803148  0.028429251191422353   \n",
      "4  0.5530563131446866   ...    0.021215811724083378   0.01614957064721532   \n",
      "\n",
      "                  std28                  std29                 std30  \\\n",
      "0  0.023998392396840817   0.015884447020578795  0.020840388593604587   \n",
      "1  0.026129803050797526    0.02183841031542601  0.009046211433627497   \n",
      "2  0.027782802810656353    0.01726926122492386   0.02020744699518808   \n",
      "3  0.014736279519637819  0.0025605492556503443  0.006249074196904105   \n",
      "4  0.019531071635425206   0.009488533436306052  0.011435272679992654   \n",
      "\n",
      "                  std31                  std32                  std33  \\\n",
      "0  0.010203291626409077   0.012468692458164746   0.005193288275889477   \n",
      "1  0.015773622927375826   0.011016627186014838  0.0053442865868248215   \n",
      "2  0.014235038380495377   0.010520866150524357   0.005646320526340706   \n",
      "3  0.012040713727260007   0.010140995680127517   0.013420193426283786   \n",
      "4  0.008396561352641302  0.0062898017543584995   0.004602128931831703   \n",
      "\n",
      "                  std34 Emotion  \n",
      "0  0.011701541489217584   anger  \n",
      "1  0.012364836923883168   anger  \n",
      "2  0.010771332856236623   anger  \n",
      "3  0.008774732676597318   anger  \n",
      "4  0.007484708366441009   anger  \n",
      "\n",
      "[5 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "featuresNames = numpy.array(\n",
    "    [\"ZCR\",\"Energy\",\"Entropy Of Enery\",\n",
    "     \"Spectral Centroid\", \"Pitch\", \"Spectral Entropy\",\n",
    "     \"Spectral Flux\", \"Spectral Roll-off\", \"MFCC1\",\n",
    "     \"MFCC2\", \"MFCC3\", \"MFCC4\", \"MFCC5\", \"MFCC6\",\n",
    "     \"MFCC7\", \"MFCC8\", \"MFCC9\", \"MFCC10\", \"MFCC11\",\n",
    "     \"MFCC12\", \"MFCC13\", \n",
    "     \"Chroma Vector1\",\n",
    "     \"Chroma Vector2\",\n",
    "     \"Chroma Vector3\",\n",
    "     \"Chroma Vector4\",\n",
    "     \"Chroma Vector5\",\n",
    "     \"Chroma Vector6\",\n",
    "     \"Chroma Vector7\",\n",
    "     \"Chroma Vector8\",\n",
    "     \"Chroma Vector9\",\n",
    "     \"Chroma Vector10\",\n",
    "     \"Chroma Vector11\",\n",
    "     \"Chroma Vector12\",\n",
    "     \"Chroma Vector std\",\n",
    "     \"std1\", \"std2\", \"std3\",\"std4\",\"std5\", \"std6\",\n",
    "     \"std7\",\"std8\",\"std9\",\"std10\",\"std11\",\"std12\",\n",
    "     \"std13\",\"std14\",\"std15\",\"std16\",\"std17\",\"std18\",\n",
    "     \"std19\",\"std20\",\"std21\",\"std22\",\"std23\",\n",
    "     \"std24\", \"std25\", \"std26\",\"std27\",\"std28\", \"std29\",\n",
    "     \"std30\",\"std31\",\"std32\",\"std33\",\"std34\",\n",
    "     \"Emotion\"])\n",
    "\n",
    "[features, classNames, _] = dirsWavFeatureExtraction([\"../YoutubeDownload/anger/\",\n",
    "                                                      \"../YoutubeDownload/sadness/\",\n",
    "                                                      \"../YoutubeDownload/disgust/\",\n",
    "                                                      \"../YoutubeDownload/fear/\",\n",
    "                                                      \"../YoutubeDownload/happiness/\",\n",
    "                                                      \"../YoutubeDownload/surprise/\",\n",
    "                                                     ]\n",
    "                                                      1.0, 1.0, 0.050, 0.050, False);\n",
    "\n",
    "print(classNames)\n",
    "print (\"Conversion de lista de matrices a una sola matriz\")\n",
    "[X, y] = utilities.listOfFeatures2Matrix(features)\n",
    "\n",
    "files_anger = len(next(os.walk(\"../YoutubeDownload/anger/\"))[2]) # files\n",
    "files_sadness = len(next(os.walk(\"../YoutubeDownload/sadness/\"))[2]) # files\n",
    "files_disgust = len(next(os.walk(\"../YoutubeDownload/disgust/\"))[2]) # files\n",
    "files_fear = len(next(os.walk(\"../YoutubeDownload/fear/\"))[2]) # files\n",
    "files_hapiness = len(next(os.walk(\"../YoutubeDownload/happiness/\"))[2]) # files\n",
    "files_surprice = len(next(os.walk(\"../YoutubeDownload/surprise/\"))[2]) # files\n",
    "\n",
    "print(files_anger)\n",
    "print(files_sadness)\n",
    "print(files_disgust)\n",
    "print(files_fear)\n",
    "print(files_hapiness)\n",
    "print(files_surprice)\n",
    "\n",
    "w = []\n",
    "for i in range(files_anger):\n",
    "    w.append(\"anger\")\n",
    "    \n",
    "for i in range(files_sadness):\n",
    "    w.append(\"sadness\")\n",
    "    \n",
    "for i in range(files_disgust):\n",
    "    w.append(\"disgust\")\n",
    "    \n",
    "for i in range(files_fear):\n",
    "    w.append(\"fear\")\n",
    "    \n",
    "for i in range(files_hapiness):\n",
    "    w.append(\"hapiness\")\n",
    "    \n",
    "for i in range(files_surprice):\n",
    "    w.append(\"surprice\")\n",
    "    \n",
    "    \n",
    "\n",
    "w = numpy.array(w)\n",
    "dataset = numpy.hstack((X,w.reshape(X.shape[0],1)))\n",
    "df = pd.DataFrame(dataset, columns=featuresNames)\n",
    "\n",
    "print(df.head())\n",
    "df.to_csv('dataset_emotion.csv', header=True, sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
